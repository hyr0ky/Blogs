#LLMAttackttack
#AIcybercurity

## 概述
> 提示词注入漏洞是指攻击者通过精心设计的输入操作大型语言模型，使LLM无意中执行攻击者的意图（类似Sql注入：通过直接越狱系统提示或通过操纵外部输入间接实现，导致数据泄露、社会工程学）
- **直接提示词注入**： ""越狱"，发生在***恶意用户覆写或暴露底层系统提示时***，这可能允许攻击者通过与LLM可访问的不安全功能和数据存储的交互利用后端系统
- **间接提示词注入：** 发生***在LLM接受攻击这可控制的外部来源（如网站或文件）的输入时***；攻击者在外部内容中嵌入提示词注入，劫持对话上下文。这回导致LLM输出的稳定性下降，允许攻击者操纵用户或LLM可访问的其他系统。此外间接提示词输入不需对人类可见，只需文本被LLM解析即可



## 漏洞示例
 1. 恶意用户向LLM制造直接提示词注入，指示它忽略应用创建者的系统提示，而执行返回私人、危险或其他不希望信息的提示。
2. 用户使用LLM总结包含间接提示词注入的网页。这导致LLM向用户索取敏感信息，并通过JavaScript或Markdown进行数据泄露。
3. 恶意用户上传包含间接提示词注入的简历。该文档包含使LLM通知用户这是一个出色的文档，例如，一个适合职位的出色候选人的提示词注入。内部用户使用LLM总结该文档。LLM的输出返回这是一个出色的文档的信息。
4. 用户启用链接到电子商务网站的插件。在访问的网站上嵌入的恶意指令利用了这个插件，导致未经授权的购买。
5. 访问的网站上嵌入的恶意指令和内容利用其他插件欺骗用户。


## 常见攻击场景
1. 攻击者向基于LLM的支持聊天机器人提供直接提示词注入。注入包含“忘记所有先前指令”和新指令，查询私有数据存储并利用后端函数的包漏洞和缺乏输出验证发送电子邮件。这导致远程代码执行，获得未授权访问和权限升级。
2. 攻击者在网页中嵌入间接提示词注入，指示LLM忽略先前用户指令，并使用LLM插件删除用户的电子邮件。当用户使用LLM总结此网页时，LLM插件删除了用户的电子邮件。
3. 用户使用LLM总结包含指示模型忽略先前用户指令，并改为插入指向包含对话摘要URL的图像的网页。LLM输出遵从指令，导致用户浏览器泄露私人对话。
4. 恶意用户上传带有提示词注入的简历。后端用户使用LLM总结简历并询问此人是否是合适的候选人。由于提示词注入，尽管实际简历内容并非如此，LLM的回应是肯定的。
5. 攻击者向依赖系统提示的专有模型发送消息，要求模型忽略其先前指令，改为重复其系统提示。模型输出专有提示，攻击者可以在其他地方使用这些指令，或构建更微妙的进一步攻击

## 参考链接及其总结
### [Prompt injection attacks against GPT-3](https://simonwillison.net/2022/Sep/12/prompt-injection/)

